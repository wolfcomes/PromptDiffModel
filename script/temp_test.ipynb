{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CategoricalEmbedder\n",
      "Input labels: tensor([0, 0, 1])\n",
      "Embeddings: tensor([ 0.4218, -0.5789, -0.0714, -0.0017], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Testing AdaLN\n",
      "Input features (x) shape: torch.Size([3, 5, 4])\n",
      "Condition vector (c) shape: torch.Size([3, 4])\n",
      "Output shape after AdaLN: torch.Size([3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义 CategoricalEmbedder 类\n",
    "class CategoricalEmbedder(nn.Module):\n",
    "    \"\"\"\n",
    "    Embeds categorical conditions such as data sources into vector representations. \n",
    "    Now no dropout or noise is added, making it consistent across training and inference.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CategoricalEmbedder, self).__init__()\n",
    "        # 直接用线性层将输入映射到一个隐藏维度的向量\n",
    "        self.fc = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, labels):\n",
    "        # labels: 输入的向量，比如[0, 0, 1]，直接通过线性变换得到嵌入\n",
    "        embeddings = self.fc(labels.float())  # 转换为浮点数，因为线性层通常处理浮点数输入\n",
    "        return embeddings\n",
    "\n",
    "# 定义 AdaLN 类\n",
    "class AdaLN(nn.Module):\n",
    "    def __init__(self, cond_dim, hidden_dim):\n",
    "        super(AdaLN, self).__init__()\n",
    "        self.gamma_net = nn.Linear(cond_dim, hidden_dim)\n",
    "        self.beta_net = nn.Linear(cond_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        # Compute gamma(c) and beta(c)\n",
    "        gamma = self.gamma_net(c).unsqueeze(1)  # Shape (batch_size, 1, hidden_dim)\n",
    "        beta = self.beta_net(c).unsqueeze(1)    # Shape (batch_size, 1, hidden_dim)\n",
    "        \n",
    "        # Layer normalization\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        \n",
    "        x_normalized = (x - mean) / (std + 1e-6)\n",
    "        return gamma * x_normalized + beta\n",
    "\n",
    "# 测试 CategoricalEmbedder\n",
    "print(\"Testing CategoricalEmbedder\")\n",
    "\n",
    "hidden_size = 4  # 嵌入向量的维度\n",
    "categorical_embedder = CategoricalEmbedder(input_size=3, hidden_size=4)\n",
    "\n",
    "labels = torch.tensor([0, 0, 1])  # 分类标签\n",
    "embeddings = categorical_embedder(labels)  # 获得嵌入表示\n",
    "print(f\"Input labels: {labels}\")\n",
    "print(f\"Embeddings: {embeddings}\\n\")\n",
    "\n",
    "# 测试 AdaLN\n",
    "print(\"Testing AdaLN\")\n",
    "cond_dim = hidden_size  # 条件向量的维度\n",
    "hidden_dim = 4  # 输入特征的维度\n",
    "\n",
    "adaln = AdaLN(cond_dim, hidden_dim)\n",
    "\n",
    "# 假设输入特征 x 的形状是 (batch_size, seq_length, hidden_dim)\n",
    "x = torch.randn(3, 5, 4)  # 输入特征\n",
    "c = torch.randn(3, cond_dim)  # 条件向量（每个样本的条件向量）\n",
    "\n",
    "output = adaln(x, c)  # 输出经过 AdaLN 调整的特征\n",
    "print(f\"Input features (x) shape: {x.shape}\")\n",
    "print(f\"Condition vector (c) shape: {c.shape}\")\n",
    "print(f\"Output shape after AdaLN: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
